name: GitHub DACKAR test
run-name: ${{ github.actor }} is testing out DACKAR
on: [push, pull_request]

concurrency:
  # Here the group is defined by the head_ref of the PR
  group: ${{ github.head_ref }}
  # Here we specify that we'll cancel any "in progress" workflow of the same group. Thus if we push, ammend a commit and push
  # again the previous workflow will be cancelled, thus saving us github action build minutes and avoid any conflicts
  cancel-in-progress: true

jobs:
  Test-DACKAR-Linux:
    # runs-on: [self-hosted, ubuntu-latest]
    # runs-on: ${{ fromJSON('["ubuntu-latest", "self-hosted"]')[github.repository == 'github/docs-internal'] }}
    runs-on: ubuntu-latest
    steps:
      - name: Setup Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniconda-version: "latest"
          channels: conda-forge, defaults
          use-only-tar-bz2: true  # IMPORTANT: This needs to be set for caching to work properly!
          auto-update-conda: true
          auto-activate-base: true

      - name: Job Information
        run: |
          echo " The job was automatically triggered by a ${{ github.event_name }} event."
          echo " This job is now running on a ${{ runner.os }} server"
          echo " The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}."

      - name: Fetch and Branch
        uses: actions/checkout@v3

      - name: Install DACKAR Required Libraries
        # Either fix scikit-learn==1.5 to allow quantulum3 to use the pretrained classifier or
        # Run "quantulum3-training -s" to retrain classifier

        run: |
          pwd
          conda create -n dackar_libs python=3.11
          conda init bash && source ~/.bashrc && conda activate dackar_libs
          pip install spacy==3.5 stumpy textacy matplotlib nltk coreferee beautifulsoup4 networkx pysbd tomli numerizer autocorrect pywsd openpyxl quantulum3[classifier] numpy==1.26 scikit-learn pyspellchecker contextualSpellCheck pandas
          pip install neo4j jupyterlab
          pip install pytest
      # python -m spacy download en_core_web_lg [for some reason, GitHub machine complains this command]
      - name: Download trained models
        run: |
          conda init bash && source ~/.bashrc && conda activate dackar_libs
          python -m coreferee install en
          python -m nltk.downloader all
          pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl
          quantulum3-training -s

      - name: Test
        run: |
          cd tests
          conda init bash && source ~/.bashrc && conda activate dackar_libs
          pytest


  Test-DACKAR-Macos:
    runs-on: macos-latest
    steps:
      - name: Setup Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniconda-version: "latest"
          channels: conda-forge, defaults
          use-only-tar-bz2: true  # IMPORTANT: This needs to be set for caching to work properly!
          auto-update-conda: true
          auto-activate-base: true

      - name: Job Information
        run: |
          echo " The job was automatically triggered by a ${{ github.event_name }} event."
          echo " This job is now running on a ${{ runner.os }} server"
          echo " The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}."

      - name: Fetch and Branch
        uses: actions/checkout@v3

      - name: Install DACKAR Required Libraries
        run: |
          pwd
          conda create -n dackar_libs python=3.11
          conda init zsh && source ~/.zshrc && conda activate dackar_libs
          pip install spacy==3.5 stumpy textacy matplotlib nltk coreferee beautifulsoup4 networkx pysbd tomli numerizer autocorrect pywsd openpyxl quantulum3[classifier] numpy==1.26 scikit-learn pyspellchecker contextualSpellCheck pandas
          pip install neo4j jupyterlab
          pip install pytest

      # python -m spacy download en_core_web_lg [for some reason, GitHub machine complains this command]
      - name: Download trained models
        run: |
          conda init zsh && source ~/.zshrc && conda activate dackar_libs
          python -m coreferee install en
          python -m nltk.downloader all
          pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl
          quantulum3-training -s

      - name: Test
        run: |
          cd tests
          conda init zsh && source ~/.zshrc && conda activate dackar_libs
          pytest


  Test-DACKAR-Windows:
    runs-on: windows-latest
    steps:
      - name: Setup Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniconda-version: "latest"
          channels: conda-forge, defaults
          use-only-tar-bz2: true  # IMPORTANT: This needs to be set for caching to work properly!
          activate-environment: dackar_libs
          auto-update-conda: true
          auto-activate-base: false
      - name: Job Information
        run: |
          echo " The job was automatically triggered by a ${{ github.event_name }} event."
          echo " This job is now running on a ${{ runner.os }} server"
          echo " The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}."

      - name: Fetch and Branch
        uses: actions/checkout@v3

      - name: Install DACKAR Required Libraries
        run: |
          echo " Create dackar_libs"
          conda install python=3.11
          echo " Conda information"
          conda info
          echo " Activate Dackar conda environment"
          pip install spacy==3.5 textacy matplotlib nltk coreferee beautifulsoup4 networkx pysbd tomli numerizer autocorrect pywsd openpyxl quantulum3[classifier] numpy==1.26 scikit-learn pyspellchecker contextualSpellCheck pandas
          pip install neo4j jupyterlab
          pip install pytest
          conda install -c conda-forge stumpy
          conda list
          which python

      # python -m spacy download en_core_web_lg [for some reason, GitHub machine complains this command]
      # python -m spacy download en_core_web_lg
      # pip install numba
      - name: Download trained models
        run: |
          pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl
          python -m coreferee install en
          python -m nltk.downloader all
          quantulum3-training -s

      - name: Test
        run: |
          cd tests
          pytest

